{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion\n",
    "from random import choice\n",
    "\n",
    "import py4DSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fp = \"/home/ben/Data/20190128_ClassificationData/EASY_binDiffraction4.h5\"\n",
    "fp = \"/Users/Ben/Desktop/EASY_binDiffraction4_no_datacube.h5\"\n",
    "browser = py4DSTEM.file.readwrite.FileBrowser(fp)\n",
    "ave_im = browser.get_dataobject('average_image').data2D\n",
    "deconvolution = browser.get_dataobject('deconvolution').data2D\n",
    "bragg_peaks_by_scan_position_pla = browser.get_dataobject('braggpeak_sets_by_scan_position_pla')\n",
    "initial_classification = browser.get_dataobject('initial_classification').data2D\n",
    "#braggpeaks = browser.get_dataobject('Bragg_peaks')\n",
    "\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_Nx,Q_Ny = deconvolution.shape\n",
    "R_Nx,R_Ny = ave_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggpeak_sets_by_scan_position = [[set() for i in range(R_Ny)] for j in range(R_Nx)]\n",
    "\n",
    "for Rx in range(R_Nx):\n",
    "    for Ry in range(R_Ny):\n",
    "            indices = bragg_peaks_by_scan_position_pla.get_pointlist(Rx,Ry).data['i']\n",
    "            braggpeak_sets_by_scan_position[Rx][Ry] = set(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=0\n",
    "for Rx in range(R_Nx):\n",
    "    for Ry in range(R_Ny):\n",
    "        try:\n",
    "            N_max = max(braggpeak_sets_by_scan_position[Rx][Ry])\n",
    "            if N < N_max:\n",
    "                N = N_max\n",
    "        except ValueError:\n",
    "            pass\n",
    "N+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and ClassLabel objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(object):\n",
    "    \"\"\"\n",
    "    A classification of a 4D STEM dataset.\n",
    "    \n",
    "    A classification object consists of two states: the current state and the next state.\n",
    "    For each state, there is a:\n",
    "        classification      (shape (Rx,Ry) array of ints) the class labels k at each scan position\n",
    "        classes             (len N_classes list of ClassLabel objects) the classes\n",
    "        cost                (float) measure to minimize\n",
    "    A classification has the following methods:\n",
    "        get_new_state()            gets a possible next state, calculates its cost, and accepts or rejects the state\n",
    "        new_class(rx,ry)           generate a possible next state by seeding a new class from scan position rx,ry + NNs\n",
    "        grow_class(i)              generate a possible next state by expanding class i\n",
    "        merge_classes(i,j)         generate a possible next state by merging classes i and j\n",
    "        accept_next_state()        current state := next_state; next_state := new_state\n",
    "        reject_next_state()        current state := current_state; next_state := new_state\n",
    "        get_current_cost()         get the cost of the current state\n",
    "        get_next_cost()            get the cost of the next state\n",
    "        get_class_mask(i)          returns an (Rx,Ry) ndarray of bools specifying class i scan positions\n",
    "    The classification object may be initialized with a 2D array of ints, giving the class values k; if this is\n",
    "    provided, the classification object will initialize a set of classlabel objects accordingly.\n",
    "    \"\"\"\n",
    "    def __init__(self,R_Nx,R_Ny,N,V,thresh,alpha,unclassified_cost,\n",
    "                 braggpeak_sets_by_scan_position,grow_merge_new_ratio=[1,20,20],N_rand_positions=20,\n",
    "                 classification=None):\n",
    "        \"\"\"Accepts:\n",
    "                R_Nx,R_Ny                      (ints) scan shape\n",
    "                N                              (int) number of indexed Bragg peaks\n",
    "                V,thresh                       (floats) cost function and ClassLabel parameters\n",
    "                alpha                          (float) the cost of having additional classes\n",
    "                unclassified_cost              (float) the cost of having an unclassified pixel\n",
    "                bragg_peaks_by_scan_position   (list of lists of sets) the set of Bragg peaks by scan position\n",
    "                grow_merge_new_ratio           (length-3 list of ints) when time-evolving, ratio of grow/merge/new steps attempted\n",
    "                N_rand_positions               (int) number of random positions to select seed from\n",
    "                classification                 (shape (R_Nx,R_Ny) array of ints) an initial classification\n",
    "        \"\"\"\n",
    "        self.R_Nx,self.R_Ny,self.N = R_Nx,R_Ny,N\n",
    "        self.classification_current = -np.ones((self.R_Nx,self.R_Ny),dtype=int)   # -1 refers to a pixel which is\n",
    "        self.classification_next = -np.ones((self.R_Nx,self.R_Ny),dtype=int)      # as-yet unassigned to a class\n",
    "        self.classes_current = []\n",
    "        self.classes_next = []\n",
    "        self.N_classes_current = 0\n",
    "        self.N_classes_next = 0\n",
    "        self.class_indices_current = []\n",
    "        self.class_indices_next = []\n",
    "        self.class_index_current = 0\n",
    "        self.class_index_next = 0\n",
    "        self.cost_current = 0\n",
    "        self.cost_next = 0\n",
    "        \n",
    "        self.delta_forward = -2*np.ones((self.R_Nx,self.R_Ny),dtype=int)     # -2 refers to unchanged pixels\n",
    "        self.delta_backward = -2*np.ones((self.R_Nx,self.R_Ny),dtype=int)    # 0 and -1 are already in use!\n",
    "        self.t=0\n",
    "        self.N_rand_positions = N_rand_positions\n",
    "        self.get_grow_merge_new_steps(grow_merge_new_ratio)            # Defines self.steps, specifying when\n",
    "                                                                       # to attempt which type of new state\n",
    "        self.alpha = alpha\n",
    "        self.V = V\n",
    "        self.thresh = thresh\n",
    "        self.braggpeak_sets_by_scan_position = braggpeak_sets_by_scan_position\n",
    "        self.unclassified_cost = unclassified_cost\n",
    "        \n",
    "        if classification is not None:\n",
    "            self.get_current_state_from_classification(classification)\n",
    "            self.get_next_state_from_current_state()\n",
    "    \n",
    "    def get_new_state(self, step_type=None):\n",
    "        \"\"\"Updates to the next state.\n",
    "        \n",
    "           Assumes next_state begins in the same state as current_state; this is ensured as long as\n",
    "           self.accept_next_state() or self.reject_next_state() has been run since the last self. get_new_state() call.\n",
    "           \n",
    "           Generates two (R_Nx,R_Ny) arrays of ints: delta_forward and delta_backward. \n",
    "           These store changes so that rejected changes in next state can be reverted if needed.\n",
    "           In both, -2 represents no change, a number represents the class to change this pixel to.\n",
    "  \n",
    "           delta_forward and delta_backward are generated by calling new_class, grow_class, or merge_class.\n",
    "           Which is called is controlled by the class parameter \n",
    "        \"\"\"\n",
    "                \n",
    "        COST = 0\n",
    "        \n",
    "        # Choose a new step type \n",
    "        if step_type is None:\n",
    "            step_type = self.steps[self.t%(len(self.steps))]\n",
    "        assert step_type in [1,2,3], \"step_type must be 1, 2 or 3\"\n",
    "        self.t += 1\n",
    "        if step_type==1:\n",
    "            i = self.select_a_class()\n",
    "            self.grow_class(i)\n",
    "        elif step_type==2:\n",
    "            rx,ry = self.select_new_seed_positions()\n",
    "            self.new_class(rx,ry)\n",
    "        elif step_type==3:\n",
    "            i,j = self.select_class_pair()\n",
    "            self.merge_classes(i,j)\n",
    "        else:\n",
    "            raise Exception(\"Error: step_type must be 1,2, or 3, not {}\".format(step_type))\n",
    "\n",
    "        # Time evolving the classes\n",
    "        # Get a possible the next state; calculate cost\n",
    "        self.classification_next = np.where(self.delta_forward!=-2,self.delta_forward,self.classification_next)\n",
    "        for new_class_index in self.new_class_indices:\n",
    "            mask = self.delta_forward==new_class_index\n",
    "            new_class = ClassLabel(index=new_class_index,mask=mask,N=self.N,V=self.V,thresh=self.thresh)\n",
    "            self.classes_next.append(new_class)\n",
    "            self.N_classes_next += 1\n",
    "            self.class_indices_next.append(new_class_index)\n",
    "            self.class_index_next += 1\n",
    "            assert(np.all(self.classification_next[mask] == new_class_index))\n",
    "            COST += new_class.my_cost\n",
    "        for removed_class_index in self.removed_class_indices:\n",
    "            if removed_class_index!=-1:\n",
    "                removed_class = self.get_class_next(removed_class_index)\n",
    "                self.classes_next.remove(removed_class)\n",
    "                self.N_classes_next -= 1\n",
    "                self.class_indices_next.remove(removed_class_index)\n",
    "                print('Removed class cost: {}'.format(removed_class.my_cost))\n",
    "                COST -= removed_class.my_cost\n",
    "                del removed_class\n",
    "            else:\n",
    "                mask = self.delta_backward==removed_class_index\n",
    "                COST -= self.unclassified_cost * np.sum(mask)\n",
    "        for grown_class_index in self.grown_class_indices:\n",
    "            #if grown_class_index!=-1:\n",
    "            grown_class = self.get_class_next(grown_class_index)\n",
    "            mask = self.delta_forward==grown_class_index\n",
    "            rx,ry = np.nonzero(mask)\n",
    "            cost_temp = grown_class.my_cost\n",
    "            grown_class.add_data_by_scan_position(rx,ry)\n",
    "            print('Grown class cost: {}'.format(grown_class.my_cost - cost_temp))\n",
    "            COST += (grown_class.my_cost - cost_temp)\n",
    "            #else:\n",
    "            #    mask = self.delta_forward==grown_class_index\n",
    "            #    COST += self.unclassified_cost * np.sum(mask)\n",
    "        for eroded_class_index in self.eroded_class_indices:\n",
    "            if eroded_class_index!=-1:\n",
    "                eroded_class = self.get_class_next(eroded_class_index)\n",
    "                mask = self.delta_backward==eroded_class_index\n",
    "                rx,ry = np.nonzero(mask)\n",
    "                cost_temp = eroded_class.my_cost\n",
    "                eroded_class.remove_data_by_scan_position(rx,ry)\n",
    "                COST += (eroded_class.my_cost - cost_temp)\n",
    "            else:\n",
    "                mask = self.delta_backward==eroded_class_index\n",
    "                COST -= self.unclassified_cost * np.sum(mask)\n",
    "\n",
    "        COST += self.alpha * (self.N_classes_next-self.N_classes_current)\n",
    "        COST += self.unclassified_cost * (np.sum(self.classification_next==-1)-np.sum(self.classification_current==-1))\n",
    "\n",
    "        if COST < 0:\n",
    "            self.accept_next_state()\n",
    "        else:\n",
    "            self.reject_next_state()\n",
    "\n",
    "        return COST\n",
    "\n",
    "\n",
    "    def new_class(self,rx,ry):\n",
    "        \"\"\"Generates a possible next state by seeding a new class from the scan position rx,ry and its 8 NNs.\n",
    "           Saves (as attributes of self):\n",
    "               delta_forward          the proposed changes\n",
    "               delta_backward         the current state of the changed pixels\n",
    "               new_class_indices      a list of ints containing indices for any new classes\n",
    "               removed_class_indices  a list of ints containing indices of any removed classes\n",
    "               grown_class_indices    a list of ints containing indices of classes which grew\n",
    "               eroded_class_indices   a list of ints containing indices of classes which eroded\n",
    "        \"\"\"\n",
    "        # Define objects to return\n",
    "        self.delta_forward = -2*np.ones((self.R_Nx,self.R_Ny))\n",
    "        self.delta_backward = -2*np.ones((self.R_Nx,self.R_Ny))\n",
    "        self.new_class_indices = []\n",
    "        self.removed_class_indices = []\n",
    "        self.eroded_class_indices = []\n",
    "        self.grown_class_indices = []\n",
    "        # Get set of all NN pixels, handling edges\n",
    "        rx_min = rx - 1*(rx>0)\n",
    "        ry_min = ry - 1*(ry>0)\n",
    "        rx_max = rx + 1 + 1*(rx<(self.R_Nx-1))\n",
    "        ry_max = ry + 1 + 1*(ry<(self.R_Ny-1))\n",
    "        rxx,ryy = np.meshgrid(np.arange(rx_min,rx_max),np.arange(ry_min,ry_max))\n",
    "        rx,ry = rxx.ravel(),ryy.ravel()\n",
    "        # Add the changes to delta_forward and delta_backward\n",
    "        new_class_index = self.class_index_next   # Don't increment self.class_index_next; we haven't actually added it yet!\n",
    "        eroded_classes_temp = []\n",
    "        for j in range(len(rx)):\n",
    "            i = self.classification_next[rx[j],ry[j]]\n",
    "            self.delta_backward[rx[j],ry[j]] = i\n",
    "            self.delta_forward[rx[j],ry[j]] = new_class_index\n",
    "            eroded_classes_temp.append(i)\n",
    "        # Get any new / eroded / removed classes\n",
    "        self.new_class_indices.append(new_class_index)\n",
    "        eroded_classes_temp = set(eroded_classes_temp)\n",
    "        for eroded_class_index in eroded_classes_temp:\n",
    "            if eroded_class_index not in self.classification_next[self.delta_forward==-2]:\n",
    "                self.removed_class_indices.append(eroded_class_index)\n",
    "            else:\n",
    "                self.eroded_class_indices.append(eroded_class_index)\n",
    "        return\n",
    "        \n",
    "    def grow_class(self,i):\n",
    "        \"\"\"Generates a possible next state by growing class i into adjacent cells which will reduce the total cost.\n",
    "           Saves (as attributes of self):\n",
    "               delta_forward          the proposed changes\n",
    "               delta_backward         the current state of the changed pixels\n",
    "               new_class_indices      a list of ints containing indices for any new classes\n",
    "               removed_class_indices  a list of ints containing indices of any removed classes\n",
    "               grown_class_indices    a list of ints containing indices of classes which grew\n",
    "               eroded_class_indices   a list of ints containing indices of classes which eroded\n",
    "        \"\"\"\n",
    "        # Define objects to return\n",
    "        self.delta_forward = -2*np.ones((self.R_Nx,self.R_Ny))\n",
    "        self.delta_backward = -2*np.ones((self.R_Nx,self.R_Ny))\n",
    "        self.new_class_indices = []\n",
    "        self.removed_class_indices = []\n",
    "        self.grown_class_indices = []\n",
    "        self.eroded_class_indices = []\n",
    "        # Get class, possible growth pixels\n",
    "        growing_class = self.get_class_next(i)\n",
    "        assert growing_class is not None, \"index was {}\".format(i)\n",
    "        growth_mask = np.logical_xor(growing_class.mask,binary_dilation(growing_class.mask))\n",
    "        rx,ry = np.nonzero(growth_mask)\n",
    "        # Determine if each pixel will raise or lower cost, and construct delta_forward/delta_backward\n",
    "        self.grown_class_indices = [i]\n",
    "        eroded_class_indices_temp = []\n",
    "        for j in range(len(rx)):\n",
    "            s = self.braggpeak_sets_by_scan_position[rx[j]][ry[j]] # The BPs at the cell in question\n",
    "            i_eroded = self.classification_next[rx[j],ry[j]]       # The index of the class being eroded\n",
    "            if i_eroded != -1:\n",
    "                eroded_class = self.get_class_next(i_eroded)\n",
    "                assert eroded_class is not None, \"index was {}\".format(i_eroded)\n",
    "                cost_eroded = eroded_class.cost(s)                 # The cost of this cell in the eroded class\n",
    "            else:\n",
    "                cost_eroded = unclassified_cost                    # Cost for losing an unassigned pixel\n",
    "            cost_growing = growing_class.cost(s)                   # The cost of this cell in the growing class\n",
    "            \n",
    "            if cost_growing < cost_eroded:\n",
    "                self.delta_forward[rx[j],ry[j]] = i\n",
    "                self.delta_backward[rx[j],[ry[j]]] = i_eroded\n",
    "                eroded_class_indices_temp.append(i_eroded)\n",
    "        # Get any changed or removed classes\n",
    "        eroded_class_indices_temp = set(eroded_class_indices_temp)\n",
    "        for eroded_class_index in eroded_class_indices_temp:\n",
    "            if eroded_class_index not in self.classification_next[self.delta_forward==-2]:\n",
    "                self.removed_class_indices.append(eroded_class_index)\n",
    "            else:\n",
    "                self.eroded_class_indices.append(eroded_class_index)\n",
    "        return   \n",
    "        \n",
    "    def merge_classes(self,i,j):\n",
    "        \"\"\"Generates a possible next state by merging class i into class j.\n",
    "           Saves (as attributes of self):\n",
    "               delta_forward          the proposed changes\n",
    "               delta_backward         the current state of the changed pixels\n",
    "               new_class_indices      a list of ints containing indices for any new classes\n",
    "               removed_class_indices  a list of ints containing indices of any removed classes\n",
    "               grown_class_indices    a list of ints containing indices of classes which grew\n",
    "               eroded_class_indices   a list of ints containing indices of classes which eroded\n",
    "        \"\"\"\n",
    "        # Define objects to return\n",
    "        self.delta_forward = -2*np.ones((self.R_Nx,self.R_Ny))\n",
    "        self.delta_backward = -2*np.ones((self.R_Nx,self.R_Ny))\n",
    "        self.new_class_indices = []\n",
    "        self.removed_class_indices = []\n",
    "        self.grown_class_indices = []\n",
    "        self.eroded_class_indices = []\n",
    "        # Get classes\n",
    "        growing_class = self.get_class_next(j)\n",
    "        eroding_class = self.get_class_next(i)\n",
    "        # Populate delta_forward and delta_backward\n",
    "        self.delta_forward[self.classification_current==i] = j\n",
    "        self.delta_backward[self.classification_current==i] = i\n",
    "        self.grown_class_indices.append(j)\n",
    "        self.removed_class_indices.append(i)\n",
    "        return\n",
    "\n",
    "    def accept_next_state(self):\n",
    "        \"\"\"Sets current_state := next_state; next_state := next_state.\n",
    "           Needs to update:\n",
    "               self.classification_current\n",
    "               self.classes_current\n",
    "               self.N_classes_current\n",
    "               self.class_indices_current\n",
    "               self.class_index_current\n",
    "        \"\"\"\n",
    "        # Time evolving the classes\n",
    "        # Update the current next state\n",
    "        self.classification_current = np.where(self.delta_forward!=-2,self.delta_forward,self.classification_current)     \n",
    "        for new_class_index in self.new_class_indices:\n",
    "            mask = self.delta_forward==new_class_index\n",
    "            new_class = ClassLabel(index=new_class_index,mask=mask,N=self.N,V=self.V,thresh=self.thresh)\n",
    "            self.classes_current.append(new_class)\n",
    "            self.N_classes_current += 1\n",
    "            self.class_indices_current.append(new_class_index)\n",
    "            self.class_index_current += 1\n",
    "            assert(np.all(self.classification_current[mask] == new_class_index))\n",
    "        for removed_class_index in self.removed_class_indices:\n",
    "            if removed_class_index!=-1:\n",
    "                removed_class = self.get_class_current(removed_class_index)\n",
    "                self.classes_current.remove(removed_class)\n",
    "                self.N_classes_current -= 1\n",
    "                self.class_indices_current.remove(removed_class_index)\n",
    "                del removed_class\n",
    "        for grown_class_index in self.grown_class_indices:\n",
    "            grown_class = self.get_class_current(grown_class_index)\n",
    "            mask = self.delta_forward==grown_class_index\n",
    "            rx,ry = np.nonzero(mask)\n",
    "            grown_class.add_data_by_scan_position(rx,ry)\n",
    "        for eroded_class_index in self.eroded_class_indices:\n",
    "            if eroded_class_index!=-1:\n",
    "                eroded_class = self.get_class_current(eroded_class_index)\n",
    "                mask = self.delta_backward==eroded_class_index\n",
    "                rx,ry = np.nonzero(mask)\n",
    "                eroded_class.remove_data_by_scan_position(rx,ry)\n",
    "    \n",
    "    def reject_next_state(self):\n",
    "        \"\"\"Leaves current state unchanged. Reverts next_state := current_state.\n",
    "           Needs to update:\n",
    "               self.classification_next\n",
    "               self.classes_next\n",
    "               self.N_classes_next\n",
    "               self.class_indices_next\n",
    "               self.class_index_next\n",
    "        \"\"\"       \n",
    "        # Time evolving the classes\n",
    "        # Reset the next state to the current state\n",
    "        self.classification_next = np.where(self.delta_backward!=-2,self.delta_backward,self.classification_next)      \n",
    "        for removed_class_index in self.new_class_indices:          # Remove the new classes...\n",
    "            removed_class = self.get_class_next(removed_class_index)\n",
    "            self.classes_next.remove(removed_class)\n",
    "            self.N_classes_next -= 1\n",
    "            self.class_indices_next.remove(removed_class_index)\n",
    "            del removed_class\n",
    "        for new_class_index in self.removed_class_indices:          # ...and add the removed classes\n",
    "            if new_class_index!=-1:\n",
    "                mask = self.delta_backward==new_class_index\n",
    "                new_class = ClassLabel(index=new_class_index,mask=mask,N=self.N,V=self.V,thresh=self.thresh)\n",
    "                self.classes_next.append(new_class)\n",
    "                self.N_classes_next += 1\n",
    "                self.class_indices_next.append(new_class_index)\n",
    "                assert(np.all(self.classification_next[mask] == new_class_index))\n",
    "        for eroded_class_index in self.grown_class_indices:          # Similarly, erode grown classes...\n",
    "            eroded_class = self.get_class_current(eroded_class_index)\n",
    "            mask = self.delta_forward==eroded_class_index\n",
    "            rx,ry = np.nonzero(mask)\n",
    "            eroded_class.remove_data_by_scan_position(rx,ry)\n",
    "        for grown_class_index in self.eroded_class_indices:        # ...and grow eroded ones.\n",
    "            if grown_class_index!=-1:\n",
    "                grown_class = self.get_class_next(grown_class_index)\n",
    "                mask = self.delta_backward==grown_class_index\n",
    "                rx,ry = np.nonzero(mask)\n",
    "                grown_class.add_data_by_scan_position(rx,ry)\n",
    "            \n",
    "    def get_cost_current(self):\n",
    "        self.cost_current = 0\n",
    "        for curr_class in self.classes_current:\n",
    "            self.cost_current += curr_class.my_cost\n",
    "        self.cost_current += self.alpha * self.N_classes_current\n",
    "        self.cost_current += self.unclassified_cost*np.sum(self.classification_current==-1)\n",
    "        return self.cost_current\n",
    "    \n",
    "    def get_cost_next(self):\n",
    "        self.cost_next = 0\n",
    "        for next_class in self.classes_next:\n",
    "            self.cost_next += next_class.my_cost\n",
    "        self.cost_next += self.alpha * self.N_classes_next\n",
    "        self.cost_next += self.unclassified_cost*np.sum(self.classification_next==-1)\n",
    "        return self.cost_next            \n",
    "\n",
    "    def get_grow_merge_new_steps(self, grow_merge_new_ratio):\n",
    "        \"\"\"Gets an array indicating whether to grow, merge, or create a new domain at each timestep.\n",
    "           Grow/merge/new steps at t=i are indicated by values of 1/2/3 in self.steps.\n",
    "        \"\"\"\n",
    "        grow_steps = np.zeros(np.max(grow_merge_new_ratio))\n",
    "        merge_steps = np.zeros(np.max(grow_merge_new_ratio))\n",
    "        new_steps = np.zeros(np.max(grow_merge_new_ratio))\n",
    "        grow_steps[::grow_merge_new_ratio[0]]=1\n",
    "        merge_steps[::grow_merge_new_ratio[1]]=2\n",
    "        new_steps[::grow_merge_new_ratio[2]]=3\n",
    "\n",
    "        self.steps=[]\n",
    "        all_steps = np.vstack((grow_steps,merge_steps,new_steps)).T\n",
    "        for step in all_steps:\n",
    "            for i in np.nonzero(step)[0]:\n",
    "                self.steps.append(int(step[i]))\n",
    "\n",
    "    def get_current_state_from_classification(self,classification):\n",
    "        \"\"\"Accepts a 2D array of ints. Updates self.classification_current, self.classes_current,\n",
    "           self.class_indices_current, and self.cost_current.\n",
    "        \"\"\"\n",
    "        self.classification_current = classification\n",
    "        self.classes_current = []\n",
    "        self.class_indices_current = []\n",
    "        self.N_classes_current = 0\n",
    "        self.class_index_current = 0\n",
    "        for i in range(np.max(classification)+1):\n",
    "            mask = classification==i\n",
    "            if np.any(mask):\n",
    "                new_class = ClassLabel(index=i, mask=mask, N=self.N, V=self.V, thresh=self.thresh)\n",
    "                self.classes_current.append(new_class)\n",
    "                self.N_classes_current += 1\n",
    "                self.class_index_current += 1\n",
    "                self.class_indices_current.append(i)\n",
    "        self.cost_current = self.get_cost_current()\n",
    "        \n",
    "    def get_next_state_from_current_state(self):\n",
    "        \"\"\"Updates next state to match current state. Updates self.classification_next, self.classes_next,\n",
    "           self.next, and self.cost_next.\n",
    "        \"\"\"\n",
    "        self.classification_next = np.copy(self.classification_current)\n",
    "        self.classes_next = []\n",
    "        self.class_indices_next = []\n",
    "        self.N_classes_next = 0\n",
    "        self.class_index_next = 0\n",
    "        for i in range(np.max(self.classification_next)+1):\n",
    "            mask = self.classification_next==i\n",
    "            if np.any(mask):\n",
    "                new_class = ClassLabel(index=i, mask=mask, N=self.N ,V=self.V, thresh=self.thresh)\n",
    "                self.classes_next.append(new_class)\n",
    "                self.N_classes_next += 1\n",
    "                self.class_index_next += 1\n",
    "                self.class_indices_next.append(i)\n",
    "        self.cost_next = self.get_cost_next()\n",
    "\n",
    "    def get_class_current(self,i):\n",
    "        \"\"\"If a ClassLabel instance with index=i is in the current class list, return it\n",
    "        \"\"\"\n",
    "        for curr_class in self.classes_current:\n",
    "            if curr_class.index == i:\n",
    "                return curr_class\n",
    "        return None\n",
    "    \n",
    "    def get_class_next(self,i):\n",
    "        \"\"\"If a ClassLabel instance with index=i is in the next class list, return it\n",
    "        \"\"\"\n",
    "        for next_class in self.classes_next:\n",
    "            if next_class.index == i:\n",
    "                return next_class\n",
    "        return None\n",
    "\n",
    "    def get_class_mask_current(self,i):\n",
    "        return self.classification_current==i\n",
    "    \n",
    "    def get_class_mask_next(self,i):\n",
    "        return self.classification_next==i\n",
    "    \n",
    "    def select_new_seed_positions(self):\n",
    "        rx = np.random.randint(0,self.R_Nx,size=self.N_rand_positions)\n",
    "        ry = np.random.randint(0,self.R_Ny,size=self.N_rand_positions)\n",
    "        cost_min = 1000000\n",
    "        k=-1\n",
    "        for j in range(len(rx)):\n",
    "            s = self.braggpeak_sets_by_scan_position[rx[j]][ry[j]]\n",
    "            i = self.classification_next[rx[j],ry[j]]\n",
    "            if i != -1:\n",
    "                curr_class = self.get_class_next(i)\n",
    "                assert curr_class is not None, \"index was {}\".format(i)\n",
    "                cost = curr_class.cost(s)\n",
    "            else:\n",
    "                cost = self.unclassified_cost\n",
    "            if cost < cost_min:\n",
    "                cost_min = cost\n",
    "                k=j\n",
    "        assert k!=-1, \"None of the attempted seed positions had a cost below 1000000\"\n",
    "        return rx[k],ry[k]\n",
    "    \n",
    "    def select_a_class(self):\n",
    "        return choice(self.class_indices_next)\n",
    "    \n",
    "    def select_class_pair(self):\n",
    "        i = choice(self.class_indices_next)\n",
    "        class_mask = self.get_class_mask_next(i)\n",
    "        mask = np.logical_xor(class_mask,binary_dilation(class_mask))\n",
    "        j_options = set(self.classification_next[mask])\n",
    "        try:\n",
    "            j_options.remove(-1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        assert len(j_options)>0, 'index was {}'.format(i)\n",
    "        j = choice(tuple(j_options))\n",
    "        return i,j\n",
    "    \n",
    "    def test_class_index_fidelity(self):\n",
    "        assert len(self.classes_current) == len(self.class_indices_current)\n",
    "        assert len(self.classes_next) == len(self.class_indices_next)\n",
    "        assert len(self.classes_current) == self.N_classes_current\n",
    "        assert len(self.classes_next) == self.N_classes_next\n",
    "        for index in self.class_indices_current:\n",
    "            assert index == self.get_class_current(index).index\n",
    "        for index in self.class_indices_next:\n",
    "            assert index == self.get_class_next(index).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLabel(object):\n",
    "    \"\"\"\n",
    "    The classlabel object contains data pertaining to a single classified region of real space.\n",
    "    It is a python class object used to classify space into k classes; a class class, if you will. So classy!\n",
    "    \n",
    "    This labels scan positions.  That is, this object specifies some sub-region of a 2D array (a boolean array,\n",
    "    self.mask) which are understood to be members of this class.  Physically, each class is understood to correspond\n",
    "    to a set of Bragg peaks; the relationship between these peaks in Q-space is left unspecified.\n",
    "    \n",
    "    Some diffraction pattern containing the set of Bragg peaks s is deemed more likely to be a member of the class\n",
    "    if it minimizes the cost function\n",
    "        $   c = - \\sum_i(x_i y_i w_i) + V\\sum_i(x_i \\logical_xor y_i)   $ \n",
    "    Here, the sum is over the set of all N Bragg peaks observed in all the DPs, and:\n",
    "         x              (length N array of bools) self.x[i] is True if $i\\in s$, i.e. if the i'th BP is in this DP\n",
    "         self.y         (length N array of bools) self.y[i] is True if the i'th DP is associated with this class\n",
    "         self.w         (length N array of floats) self.w[i] quantifies the strength with which we associate the\n",
    "                                                   i'th DP with the class. (We take a mean. self.y is self.w > thresh)\n",
    "         self.V         (int) how strongly we penalize x and y having differing Bragg peaks\n",
    "         \n",
    "    A ClassLabel must be initialized with some starting scan positions, rx, ry, with which to construct and initialize\n",
    "    self.mask, self.y, and self.w.  We construct self.w from the DPs indicated by rx,ry; self.w[i] is the fraction \n",
    "    of class DPs containing the i'th BP.  self.y is given by self.y = self.w > thresh; choose wisely.\n",
    "    \"\"\"    \n",
    "    def __init__(self,index,mask,N,V,thresh):\n",
    "        \"\"\"\n",
    "        Initialize a ClassLabel object. \n",
    "        \n",
    "        Accepts:\n",
    "            index       (int) the class index\n",
    "            mask        (2D array of bools) initial scan positions to include\n",
    "            N           (int) the number of indexed BPs\n",
    "            V           (float) scales penalty for nonoverlapped Bragg peaks\n",
    "            thresh      (float) min value of self.w[i] at which self.y[i] is set to True\n",
    "            \n",
    "        \"\"\"\n",
    "        # Class parameters\n",
    "        self.index = index\n",
    "        self.N = N\n",
    "        self.y = np.zeros(self.N,dtype=bool)\n",
    "        self.w = np.zeros(self.N,dtype=float)\n",
    "        self.mask = np.zeros((R_Nx,R_Ny),dtype=bool)\n",
    "        self.thresh = thresh\n",
    "        self.V = V\n",
    "        \n",
    "        # Machinery\n",
    "        self.counts_per_BP = np.zeros(self.N,dtype=int)\n",
    "        self.Ny = 0\n",
    "        self.my_cost = 0\n",
    "        \n",
    "        # Add initial points\n",
    "        rx,ry = np.nonzero(mask)\n",
    "        self.add_data_by_scan_position(rx,ry)\n",
    "        return\n",
    "\n",
    "    def add_data_by_scan_position(self,rx,ry):\n",
    "        if isinstance(rx,np.integer) and isinstance(ry,np.integer):\n",
    "            if not self.mask[rx,ry]:\n",
    "                self.mask[rx,ry] = True\n",
    "                self.Ny += 1\n",
    "                s = braggpeak_sets_by_scan_position[rx][ry]\n",
    "                for i in s:\n",
    "                    self.counts_per_BP[i] += 1\n",
    "        else:\n",
    "            assert len(rx)==len(ry)\n",
    "            for j in range(len(rx)):\n",
    "                if not self.mask[rx[j],ry[j]]:\n",
    "                    self.mask[rx[j],ry[j]] = True\n",
    "                    self.Ny += 1\n",
    "                    s = braggpeak_sets_by_scan_position[rx[j]][ry[j]]\n",
    "                    for i in s:\n",
    "                        self.counts_per_BP[i] += 1\n",
    "        self.get_w()\n",
    "        self.get_y()\n",
    "        self.get_my_cost()\n",
    "        \n",
    "    def remove_data_by_scan_position(self,rx,ry):\n",
    "        if isinstance(rx,np.integer) and isinstance(ry,np.integer):\n",
    "            if self.mask[rx,ry]:\n",
    "                self.mask[rx,ry] = False\n",
    "                self.Ny -= 1\n",
    "                s = braggpeak_sets_by_scan_position[rx][ry]\n",
    "                for i in s:\n",
    "                    self.counts_per_BP[i] -= 1\n",
    "        else:\n",
    "            assert len(rx)==len(ry)\n",
    "            for j in range(len(rx)):\n",
    "                if self.mask[rx[j],ry[j]]:\n",
    "                    self.mask[rx[j],ry[j]] = False\n",
    "                    self.Ny -= 1\n",
    "                    s = braggpeak_sets_by_scan_position[rx[j]][ry[j]]\n",
    "                    for i in s:\n",
    "                        self.counts_per_BP[i] -= 1\n",
    "        self.get_w()\n",
    "        self.get_y()\n",
    "        self.get_my_cost()\n",
    "        \n",
    "    def get_w(self):\n",
    "        self.w = self.counts_per_BP.astype(float)/self.Ny\n",
    "        \n",
    "    def get_y(self):\n",
    "        self.y = self.w > self.thresh\n",
    "        \n",
    "    def cost(self,s):\n",
    "        \"\"\" $ c = -\\sum_i(x_i y_i w_i) + V\\sum_i(x_i \\logical_xor y_i) $ \n",
    "        \"\"\"\n",
    "        if self.Ny==0:\n",
    "            return 0\n",
    "        x = self.s_to_array(s)\n",
    "        return -np.sum(x*self.y*self.w - self.V*np.logical_xor(x,self.y))\n",
    "\n",
    "    def get_my_cost(self):\n",
    "        cost = 0\n",
    "        rx,ry = np.nonzero(self.mask)\n",
    "        for i in range(len(rx)):\n",
    "            s = braggpeak_sets_by_scan_position[rx[i]][ry[i]]\n",
    "            cost += self.cost(s)\n",
    "        self.my_cost = cost\n",
    "        return self.my_cost\n",
    "    \n",
    "    def s_to_array(self,s):\n",
    "        ans = np.zeros(self.N,dtype=bool)\n",
    "        for i in s:\n",
    "            ans[i] = True\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show\n",
    "fig,ax=plt.subplots(figsize=(16,16))\n",
    "ax.matshow(initial_classification,cmap='gnuplot')\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "V = 1\n",
    "thresh = 0.1\n",
    "alpha = 5\n",
    "unclassified_cost = 10000\n",
    "grow_merge_new_ratio = [1,1000,1000]\n",
    "N_rand_positions = 20\n",
    "\n",
    "classification = Classification(R_Nx=R_Nx,R_Ny=R_Ny,N=N,\n",
    "                                V=V,thresh=thresh,alpha=alpha,unclassified_cost=unclassified_cost,\n",
    "                                grow_merge_new_ratio=grow_merge_new_ratio,\n",
    "                                N_rand_positions=N_rand_positions,\n",
    "                                braggpeak_sets_by_scan_position=braggpeak_sets_by_scan_position,\n",
    "                                #classification=np.where(initial_classification!=-1,initial_classification,0))\n",
    "                                classification=initial_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost = 11947552.081119765\n"
     ]
    }
   ],
   "source": [
    "# Show\n",
    "fig,ax=plt.subplots(figsize=(16,16))\n",
    "ax.matshow(classification.classification_current,cmap='gnuplot')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Cost = {}\".format(classification.get_cost_current()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.test_class_index_fidelity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grown class cost: 723.8509696136823\n",
      "Grown class cost: 187.39900826446276\n",
      "Grown class cost: 134.88571428571427\n",
      "Grown class cost: 533.1843763581049\n",
      "Grown class cost: 93.34731934731937\n",
      "Grown class cost: 193.22881355932202\n",
      "Grown class cost: 140.622009569378\n",
      "Grown class cost: 260.8850389470857\n",
      "Grown class cost: 353.0566037735849\n",
      "Grown class cost: 117.64282202556538\n",
      "Grown class cost: 318.9313725490196\n",
      "Grown class cost: 67.11328976034858\n",
      "Grown class cost: -32.03763440860219\n",
      "Grown class cost: -4.9869281045751634\n",
      "Grown class cost: 69.9924242424243\n",
      "Grown class cost: 181.46666666666664\n",
      "Grown class cost: 15.2225177304964\n",
      "Grown class cost: 17.388888888888893\n",
      "Grown class cost: 114.14522417153994\n",
      "Grown class cost: 245.41302472685453\n",
      "Grown class cost: 25.82795698924731\n",
      "Grown class cost: 182.57166876839008\n",
      "Grown class cost: 1.3068181818181834\n",
      "Grown class cost: 130.09660155204716\n",
      "Grown class cost: 12.557017543859615\n",
      "Grown class cost: -12.257309941520461\n",
      "Grown class cost: 155.41004784689\n",
      "Grown class cost: 33.772727272727266\n",
      "Grown class cost: 767.6179211469533\n",
      "Grown class cost: 11.833333333333332\n",
      "Grown class cost: 80.2379679144385\n",
      "Grown class cost: 32.61221927744452\n",
      "Grown class cost: -26.398684210526483\n",
      "Grown class cost: 5.900000000000001\n",
      "Grown class cost: 27.830213903743328\n",
      "Grown class cost: 201.0922077922076\n",
      "Grown class cost: -63.53647925033465\n",
      "Grown class cost: 46.477598566308245\n",
      "Grown class cost: 746.1716604244666\n",
      "Grown class cost: -21.417032233454147\n",
      "Grown class cost: 139.7504983388706\n",
      "Grown class cost: 346.83858764186635\n",
      "Grown class cost: 93.40413533834582\n",
      "Grown class cost: 78.74080882352945\n",
      "Grown class cost: 181.45512820512823\n",
      "Grown class cost: 344.84649122807014\n",
      "Grown class cost: 403.99256729610306\n",
      "Grown class cost: 251.34415584415586\n",
      "Grown class cost: 85.69006211180141\n",
      "Grown class cost: 545.0197568389053\n",
      "Grown class cost: 90.28125000000001\n",
      "Grown class cost: 123.38596491228074\n",
      "Grown class cost: 288.412449442636\n",
      "Grown class cost: 91.37356181150562\n",
      "Grown class cost: 108.76823655214031\n",
      "Grown class cost: 95.14932126696833\n",
      "Grown class cost: 55.23966813585693\n",
      "Grown class cost: 256.34332645547573\n",
      "Grown class cost: 35.13151364764266\n",
      "Grown class cost: 131.33954122189408\n",
      "Grown class cost: 181.42982456140354\n",
      "Grown class cost: 87.21477272727282\n",
      "Grown class cost: 57.619503546099295\n",
      "Grown class cost: 9.771428571428558\n",
      "Grown class cost: 18.30000000000001\n",
      "Grown class cost: 88.07368421052631\n",
      "Grown class cost: 113.68430166324904\n",
      "Grown class cost: 143.20288600288598\n",
      "Grown class cost: 25.53846153846149\n",
      "Grown class cost: 332.5025464731347\n",
      "Grown class cost: 51.0582208895554\n",
      "Grown class cost: 35.33441981747072\n",
      "Grown class cost: 241.94622500524747\n",
      "Grown class cost: -9.921218139688875\n",
      "Grown class cost: 70.5970744680851\n",
      "Grown class cost: 20.217976552322995\n",
      "Grown class cost: 84.14295392953926\n",
      "Grown class cost: 122.3353065809847\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 174.0780830327687\n",
      "Grown class cost: 74.28627450980392\n",
      "Grown class cost: 71.09278606965177\n",
      "Grown class cost: 81.5929487179487\n",
      "Grown class cost: 67.29438457175286\n",
      "Grown class cost: 43.65750915750917\n",
      "Grown class cost: 22.248576850094906\n",
      "Grown class cost: 150.4965051441137\n",
      "Grown class cost: 24.299999999999994\n",
      "Grown class cost: 107.89869835880029\n",
      "Grown class cost: 278.5435488909716\n",
      "Grown class cost: 2.2133580705010303\n",
      "Grown class cost: 39.98155533399802\n",
      "Grown class cost: 71.63863636363646\n",
      "Grown class cost: 45.027626811593905\n",
      "Grown class cost: 65.23394401572773\n",
      "Grown class cost: 239.21956740442675\n",
      "Grown class cost: 51.52041403105238\n",
      "Grown class cost: 125.16188698455784\n",
      "Grown class cost: 37.75\n",
      "Grown class cost: 122.58549089976901\n",
      "Grown class cost: 461.2452473281003\n",
      "Grown class cost: 1739.3861906400082\n",
      "Grown class cost: 81.15112994350284\n",
      "Grown class cost: 34.20238095238095\n",
      "Grown class cost: 15.304787961696206\n",
      "Grown class cost: 94.0384778012685\n",
      "Grown class cost: 31.10476190476203\n",
      "Grown class cost: 1.0369458128079145\n",
      "Grown class cost: 120.4131171946076\n",
      "Grown class cost: 14.057750759878445\n",
      "Grown class cost: 14.601604278074852\n",
      "Grown class cost: 12.285714285714285\n",
      "Grown class cost: 102.80454545454543\n",
      "Grown class cost: 21.539393939394472\n",
      "Grown class cost: 124.03174603174611\n",
      "Grown class cost: 100.26041903033035\n",
      "Grown class cost: 45.96615312791789\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 22.666666666666664\n",
      "Grown class cost: 10.13148148148147\n",
      "Grown class cost: 236.01271938473826\n",
      "Grown class cost: 1.4265049415993616\n",
      "Grown class cost: 151.86167635658944\n",
      "Grown class cost: 26.968531468531488\n",
      "Grown class cost: 26.15851684547374\n",
      "Grown class cost: 22.59409013948244\n",
      "Grown class cost: 5.303758741258747\n",
      "Grown class cost: 4.317653890824602\n",
      "Grown class cost: 894.1312774445396\n",
      "Grown class cost: 65.03030303030302\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 53.36871794871797\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 20.659523809523733\n",
      "Grown class cost: 10.48484848484849\n",
      "Grown class cost: 171.89298245614023\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 63.48480046424322\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 456.4303642334071\n",
      "Grown class cost: 28.507813989564738\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 27.853787878788125\n",
      "Grown class cost: 8.700000000000017\n",
      "Grown class cost: 9.84848484848484\n",
      "Grown class cost: 21.487264538757415\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 81.27642857142845\n",
      "Grown class cost: 20.88194444444445\n",
      "Grown class cost: 99.7884615384616\n",
      "Grown class cost: 47.42624434389137\n",
      "Grown class cost: 255.81064877091103\n",
      "Grown class cost: 27.054054054054063\n",
      "Grown class cost: 13.818055555555588\n",
      "Grown class cost: 4.5789473684210495\n",
      "Grown class cost: 13.198929527207866\n",
      "Grown class cost: 33.3960784313725\n",
      "Grown class cost: 13.48364779874214\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: -4.4999999999999964\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 160.60297790375807\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 34.20641025641024\n",
      "Grown class cost: 5.861616161616098\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 80.68582524271824\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 99.23529411764707\n",
      "Grown class cost: -27.049535603715157\n",
      "Grown class cost: 10.416666666666666\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: -7.374417249417178\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: -6.041606886657128\n",
      "Grown class cost: 25.50292397660821\n",
      "Grown class cost: 2.4683397945999843\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 22.839822873721232\n",
      "Grown class cost: 3.0310922673126726\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 21.596793248945175\n",
      "Grown class cost: 2.8717948717948687\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 41.695238095238324\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 10.054968287526663\n",
      "Grown class cost: 33.368286445012785\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 16.81368920059751\n",
      "Grown class cost: 62.14574898785424\n",
      "Grown class cost: 2.604395604395606\n",
      "Grown class cost: 15.019697535474108\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 4.346666666666664\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 18.766666666666662\n",
      "Grown class cost: 16.731489961253942\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 62.88176033934251\n",
      "Grown class cost: 184.14103466066342\n",
      "Grown class cost: 4.607350608143804\n",
      "Grown class cost: 56.12222222222222\n",
      "Grown class cost: 4.136762127410947\n",
      "Grown class cost: 37.65\n",
      "Grown class cost: 16.048127746074215\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 82.72988039655274\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: -0.2700000000001239\n",
      "Grown class cost: 2.021739130434759\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 13.696969696969632\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: -0.10684551341348403\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 3.7450980392156765\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 28.898212811101075\n",
      "Grown class cost: 10.522222222222226\n",
      "Grown class cost: 18.075724637681162\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 5.738790089253598\n",
      "Grown class cost: 6.929824561403521\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 29.775805119735764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grown class cost: 0.0\n",
      "Grown class cost: 1.9618357487922804\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 5.2454850361195895\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 18.74436090225565\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 57.636645962732885\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 26.623076923076923\n",
      "Grown class cost: 0.9128352490421037\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 14.125793650793526\n",
      "Grown class cost: 25.099999999999998\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 17.216943421542965\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 12.381315789474172\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 5.55952380952381\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 7.412442396313374\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 6.900000000000002\n",
      "Grown class cost: 21.08847000017522\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 4.891780583066378\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: -1.517477562588482\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 7.642857142857142\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 5.6157894736842024\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n",
      "Grown class cost: 0.0\n"
     ]
    }
   ],
   "source": [
    "costs = np.ones(10)\n",
    "proceed=True\n",
    "while proceed:\n",
    "    cost = classification.get_new_state(1)\n",
    "    costs[classification.t%10] = cost\n",
    "    if np.all(costs==0):\n",
    "        proceed=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost = 5256.755692928588\n"
     ]
    }
   ],
   "source": [
    "# Show\n",
    "fig,ax=plt.subplots(figsize=(16,16))\n",
    "ax.matshow(classification.classification_current,cmap='gnuplot')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Cost = {}\".format(classification.get_cost_current()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed class cost: 222.2456140350877\n",
      "Grown class cost: 434.8019802525323\n",
      "Removed class cost: -1600.1923076923122\n",
      "Grown class cost: 1622.0188679245418\n",
      "Removed class cost: 4408.423299207504\n",
      "Grown class cost: 8055.9173119093275\n",
      "Removed class cost: 45.42857142857145\n",
      "Grown class cost: 1485.8644192913393\n",
      "Removed class cost: 222.2456140350877\n",
      "Grown class cost: 1066.0669768934515\n",
      "Removed class cost: 225.9711538461537\n",
      "Grown class cost: 2324.699376947041\n",
      "Removed class cost: 149.0204081632653\n",
      "Grown class cost: 216.74043715847\n",
      "Removed class cost: 222.2456140350877\n",
      "Grown class cost: 434.8019802525323\n",
      "Removed class cost: 1508.6456692913393\n",
      "Grown class cost: 1373.6615925058543\n",
      "cost: -139.98407678548506\n",
      "Removed class cost: -120.96103896103892\n",
      "Grown class cost: 3537.654866700204\n",
      "Removed class cost: 12.75\n",
      "Grown class cost: 18.476893453145067\n",
      "Removed class cost: 196.06779661016955\n",
      "Grown class cost: 469.2478042350622\n",
      "Removed class cost: -178.1026119402986\n",
      "Grown class cost: 8977.897944415097\n",
      "Removed class cost: 379.9841269841269\n",
      "Grown class cost: 854.8510283725227\n",
      "Removed class cost: -143.718954248366\n",
      "Grown class cost: 11233.736851162506\n",
      "Removed class cost: 2664.166666666667\n",
      "Grown class cost: 2138.72761384335\n",
      "cost: -530.4390528233171\n",
      "Removed class cost: 179.0629370629371\n",
      "Grown class cost: 1222.311402661714\n",
      "Removed class cost: 58.8888888888889\n",
      "Grown class cost: 59.317595579886984\n",
      "cost: -4.571293309001916\n",
      "Removed class cost: 451.05042016806715\n",
      "Grown class cost: 0.0\n",
      "cost: -456.05042016806715\n",
      "Removed class cost: 3932.6830357142885\n",
      "Grown class cost: 886.7193843843852\n",
      "cost: -3050.9636513299033\n",
      "Removed class cost: 210.9514563106796\n",
      "Grown class cost: 1807.229134780332\n",
      "Removed class cost: 151.47482014388484\n",
      "Grown class cost: 1021.1744534291697\n",
      "Removed class cost: 251.57377049180334\n",
      "Grown class cost: 102.55336232853804\n",
      "cost: -154.0204081632653\n",
      "Removed class cost: 2.333333333333334\n",
      "Grown class cost: 0.0\n",
      "cost: -7.333333333333334\n",
      "Removed class cost: 10273.269513167203\n",
      "Grown class cost: 1564.8355412499113\n",
      "cost: -8713.433971917291\n",
      "Removed class cost: 29.142857142857142\n",
      "Grown class cost: 39.62719985197077\n",
      "Removed class cost: 196.06779661016955\n",
      "Grown class cost: 339.53395061728395\n",
      "Removed class cost: -0.5\n",
      "Grown class cost: 45.55809242007308\n",
      "Removed class cost: 19554.581655480986\n",
      "Grown class cost: 3971.7768703712736\n",
      "cost: -15587.804785109713\n",
      "Removed class cost: 146.4727272727272\n",
      "Grown class cost: 142.2097649186256\n",
      "cost: -9.262962354101603\n",
      "Removed class cost: 6009.372703412072\n",
      "Grown class cost: 5059.324936992869\n",
      "cost: -955.0477664192031\n",
      "Removed class cost: 17898.040164621238\n",
      "Grown class cost: 14145.203746138599\n",
      "cost: -3757.8364184826387\n",
      "Removed class cost: -1605.1815856777448\n",
      "Grown class cost: -1568.6207396664252\n",
      "Removed class cost: -143.718954248366\n",
      "Grown class cost: 10688.552974098655\n",
      "Removed class cost: -1644.8087855297156\n",
      "Grown class cost: 0.0\n",
      "Removed class cost: 210.9514563106796\n",
      "Grown class cost: 1801.112602826439\n",
      "Removed class cost: 62.80952380952381\n",
      "Grown class cost: 71.71654144029708\n",
      "Removed class cost: 278.9240506329113\n",
      "Grown class cost: 692.4928315210473\n",
      "Removed class cost: 96.29268292682927\n",
      "Grown class cost: 186.9797253106606\n",
      "Removed class cost: -10.409090909090922\n",
      "Grown class cost: 206.9214082503556\n",
      "Removed class cost: 80.4375\n",
      "Grown class cost: 324.6036111629064\n",
      "Removed class cost: 200.30952380952374\n",
      "Grown class cost: 2732.959979889392\n",
      "Removed class cost: 200.30952380952374\n",
      "Grown class cost: 0.0\n",
      "cost: -205.30952380952374\n",
      "Removed class cost: 7.166666666666668\n",
      "Grown class cost: 0.0\n",
      "cost: -12.166666666666668\n",
      "Removed class cost: 1645.1848341232226\n",
      "Grown class cost: 1738.9746148938168\n",
      "Removed class cost: 506.7365591397851\n",
      "Grown class cost: 2714.8922753547017\n",
      "Removed class cost: 210.9514563106796\n",
      "Grown class cost: 0.0\n",
      "cost: -215.9514563106796\n",
      "Removed class cost: 2670.8236714975897\n",
      "Grown class cost: 38.611907243355915\n",
      "cost: -2637.211764254234\n",
      "Removed class cost: 113.56250000000003\n",
      "Grown class cost: 1371.2454262272659\n",
      "Removed class cost: -0.5\n",
      "Grown class cost: 39.62719985197077\n",
      "Removed class cost: 31.047058823529426\n",
      "Grown class cost: 1578.9932338254912\n",
      "Removed class cost: 2589.2410256410258\n",
      "Grown class cost: 4101.106856489783\n",
      "Removed class cost: 23912.400311063713\n",
      "Grown class cost: 16438.15404034518\n",
      "cost: -7479.246270718533\n",
      "Removed class cost: 526.6577181208055\n",
      "Grown class cost: 1952.9374629770666\n",
      "Removed class cost: 251.27999999999994\n",
      "Grown class cost: 692.516767197114\n",
      "Removed class cost: 384.95061728395063\n",
      "Grown class cost: 162.18917490058084\n",
      "cost: -227.7614423833698\n",
      "Removed class cost: 526.6577181208055\n",
      "Grown class cost: 1032.024896362475\n",
      "Removed class cost: 251.27999999999994\n",
      "Grown class cost: 1094.4271033077666\n",
      "Removed class cost: 57.28888888888889\n",
      "Grown class cost: 1418.3120741919054\n",
      "Removed class cost: 17488.927779053043\n",
      "Grown class cost: 18347.396052222542\n",
      "Removed class cost: 2589.2410256410258\n",
      "Grown class cost: 13263.24813857875\n",
      "Removed class cost: 18378.443111046072\n",
      "Grown class cost: 0.0\n",
      "cost: -18383.443111046072\n",
      "Removed class cost: 251.57377049180334\n",
      "Grown class cost: 584.5751910321451\n",
      "Removed class cost: 9171.217948717944\n",
      "Grown class cost: 163.34603903559128\n",
      "cost: -9012.871909682352\n",
      "Removed class cost: 2752.587064676617\n",
      "Grown class cost: -336.0226339820965\n",
      "cost: -3093.6096986587136\n",
      "Removed class cost: 25.38461538461536\n",
      "Grown class cost: 379.3298593567888\n",
      "Removed class cost: 57.28888888888889\n",
      "Grown class cost: 608.3179608175742\n",
      "Removed class cost: 2287.9572649572647\n",
      "Grown class cost: 1557.1632405869314\n",
      "cost: -735.7940243703333\n",
      "Removed class cost: 106.40740740740739\n",
      "Grown class cost: 150.69739683763328\n",
      "Removed class cost: 1526.5708154506467\n",
      "Grown class cost: 1469.2819265617577\n",
      "cost: -62.288888888889005\n",
      "Removed class cost: -0.5\n",
      "Grown class cost: 45.37478247619583\n",
      "Removed class cost: 3178.2480620155034\n",
      "Grown class cost: -24.2058556580364\n",
      "cost: -3207.4539176735398\n",
      "Removed class cost: 4061.1658615136857\n",
      "Grown class cost: 4221.430536130541\n",
      "Removed class cost: 4061.1658615136857\n",
      "Grown class cost: 5476.153517789397\n",
      "Removed class cost: 1526.5708154506467\n",
      "Grown class cost: 1363.1257296882504\n",
      "cost: -168.44508576239627\n",
      "Removed class cost: 25404.029039412115\n",
      "Grown class cost: 18820.17821420014\n",
      "cost: -6588.8508252119755\n",
      "Removed class cost: -0.5\n",
      "Grown class cost: 0.0\n",
      "cost: -4.5\n",
      "Removed class cost: -182.99439252336498\n",
      "Grown class cost: -22.95269296291474\n",
      "Removed class cost: 12.662691652469883\n",
      "Grown class cost: 387.7072849132346\n",
      "Removed class cost: 251.27999999999994\n",
      "Grown class cost: 691.2404567044723\n",
      "Removed class cost: 35.61538461538462\n",
      "Grown class cost: 0.0\n",
      "cost: -40.61538461538462\n",
      "Removed class cost: 4061.1658615136857\n",
      "Grown class cost: 4232.35270565397\n",
      "Removed class cost: -182.99439252336498\n",
      "Grown class cost: 12044.38021595257\n",
      "Removed class cost: 4285.891167192432\n",
      "Grown class cost: 114.57637102191802\n",
      "cost: -4176.314796170514\n",
      "Removed class cost: 4061.1658615136857\n",
      "Grown class cost: 5468.375533646184\n",
      "Removed class cost: 251.57377049180334\n",
      "Grown class cost: 581.3708906505744\n",
      "Removed class cost: 23366.42413487148\n",
      "Grown class cost: 9509.734093669613\n",
      "cost: -13861.690041201866\n",
      "Removed class cost: 35679.590252213544\n",
      "Grown class cost: 29404.448052619555\n",
      "cost: -6280.142199593989\n",
      "Removed class cost: 4246.815151515157\n",
      "Grown class cost: 377.4827551077833\n",
      "cost: -3874.3323964073734\n",
      "Removed class cost: 251.57377049180334\n",
      "Grown class cost: 579.2024517852151\n",
      "Removed class cost: -182.99439252336498\n",
      "Grown class cost: 4900.717083097126\n",
      "Removed class cost: -182.99439252336498\n",
      "Grown class cost: 0.0\n",
      "Removed class cost: -182.99439252336498\n",
      "Grown class cost: 0.0\n",
      "Removed class cost: 4061.1658615136857\n",
      "Grown class cost: 5426.240163817121\n",
      "Removed class cost: 40939.3705064268\n",
      "Grown class cost: 31416.341716316805\n",
      "cost: -9528.028790109995\n",
      "Removed class cost: 35477.50757783049\n",
      "Grown class cost: 40547.07975114863\n",
      "Removed class cost: 40364.08535862526\n",
      "Grown class cost: 4886.577780794774\n",
      "cost: -35482.50757783049\n",
      "Removed class cost: 251.57377049180334\n",
      "Grown class cost: 575.2851478015364\n",
      "Removed class cost: 251.57377049180334\n",
      "Grown class cost: 0.0\n",
      "cost: -256.5737704918033\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "index was 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1d91881e8ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_new_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cost: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-61c9724b1754>\u001b[0m in \u001b[0;36mget_new_state\u001b[0;34m(self, step_type)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstep_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_class_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-61c9724b1754>\u001b[0m in \u001b[0;36mselect_class_pair\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index was {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: index was 20"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    cost = classification.get_new_state(3)\n",
    "    if cost<0:\n",
    "        print('cost: {}'.format(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "fig,ax=plt.subplots(figsize=(16,16))\n",
    "ax.matshow(classification.classification_current,cmap='gnuplot')\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Cost = {}\".format(classification.get_cost_current()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
